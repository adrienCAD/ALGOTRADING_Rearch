{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Trend-Following strategy\n",
    "\n",
    "## Background\n",
    "\n",
    "Applying a Simple Trend-Following strategy, where trades are made based on the direction of recent price movements. In this specific case, the strategy is based on the percentage change in the OHLC (open, high, low, close) prices, with a buy signal generated if the percentage change is positive and a sell signal generated if the percentage change is negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import sys\n",
    "sys.path.append('../functions_library')\n",
    "\n",
    "from functions import ROC, model_selection, Backtesting\n",
    "\n",
    "#import sklearn \n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "import sklearn.ensemble\n",
    "\n",
    "# Classification Metrics \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, auc #plot_roc_curve, auc\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "\n",
    "# ML models \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "import xgboost as xgb\n",
    "\n",
    "# libraries for Shapely analysis\n",
    "import shap \n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## 1. Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the CSV file into Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-08-17 04:00:00</th>\n",
       "      <td>301.13</td>\n",
       "      <td>302.57</td>\n",
       "      <td>298.0</td>\n",
       "      <td>301.61</td>\n",
       "      <td>125.66877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-17 05:00:00</th>\n",
       "      <td>301.61</td>\n",
       "      <td>303.28</td>\n",
       "      <td>300.0</td>\n",
       "      <td>303.10</td>\n",
       "      <td>377.67246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-17 06:00:00</th>\n",
       "      <td>302.40</td>\n",
       "      <td>304.44</td>\n",
       "      <td>301.9</td>\n",
       "      <td>302.68</td>\n",
       "      <td>303.86672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-17 07:00:00</th>\n",
       "      <td>302.68</td>\n",
       "      <td>307.96</td>\n",
       "      <td>302.6</td>\n",
       "      <td>307.96</td>\n",
       "      <td>754.74510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-17 08:00:00</th>\n",
       "      <td>307.95</td>\n",
       "      <td>309.97</td>\n",
       "      <td>307.0</td>\n",
       "      <td>308.62</td>\n",
       "      <td>150.75029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       open    high    low   close     volume\n",
       "timestamp                                                    \n",
       "2017-08-17 04:00:00  301.13  302.57  298.0  301.61  125.66877\n",
       "2017-08-17 05:00:00  301.61  303.28  300.0  303.10  377.67246\n",
       "2017-08-17 06:00:00  302.40  304.44  301.9  302.68  303.86672\n",
       "2017-08-17 07:00:00  302.68  307.96  302.6  307.96  754.74510\n",
       "2017-08-17 08:00:00  307.95  309.97  307.0  308.62  150.75029"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the OHLCV dataset into a Pandas Dataframe\n",
    "trading_df = pd.read_csv(\n",
    "    Path(\"../Resources/ETHUSDT-1h-data.csv\"), \n",
    "    index_col=\"timestamp\", \n",
    "    infer_datetime_format=True, \n",
    "    parse_dates=True\n",
    ")\n",
    "\n",
    "trading_df = trading_df.drop([\"close_time\",\"quote_av\",\"trades\",\"tb_base_av\",\"tb_quote_av\",\"ignore\"], axis =1)\n",
    "\n",
    "# Review the DataFrame\n",
    "trading_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a daily return values column to the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>actual_returns</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-08-17 05:00:00</th>\n",
       "      <td>301.61</td>\n",
       "      <td>303.28</td>\n",
       "      <td>300.00</td>\n",
       "      <td>303.10</td>\n",
       "      <td>377.67246</td>\n",
       "      <td>0.004940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-17 06:00:00</th>\n",
       "      <td>302.40</td>\n",
       "      <td>304.44</td>\n",
       "      <td>301.90</td>\n",
       "      <td>302.68</td>\n",
       "      <td>303.86672</td>\n",
       "      <td>-0.001386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-17 07:00:00</th>\n",
       "      <td>302.68</td>\n",
       "      <td>307.96</td>\n",
       "      <td>302.60</td>\n",
       "      <td>307.96</td>\n",
       "      <td>754.74510</td>\n",
       "      <td>0.017444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-17 08:00:00</th>\n",
       "      <td>307.95</td>\n",
       "      <td>309.97</td>\n",
       "      <td>307.00</td>\n",
       "      <td>308.62</td>\n",
       "      <td>150.75029</td>\n",
       "      <td>0.002143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-17 09:00:00</th>\n",
       "      <td>308.62</td>\n",
       "      <td>312.00</td>\n",
       "      <td>308.62</td>\n",
       "      <td>310.00</td>\n",
       "      <td>469.27879</td>\n",
       "      <td>0.004472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       open    high     low   close     volume  actual_returns\n",
       "timestamp                                                                     \n",
       "2017-08-17 05:00:00  301.61  303.28  300.00  303.10  377.67246        0.004940\n",
       "2017-08-17 06:00:00  302.40  304.44  301.90  302.68  303.86672       -0.001386\n",
       "2017-08-17 07:00:00  302.68  307.96  302.60  307.96  754.74510        0.017444\n",
       "2017-08-17 08:00:00  307.95  309.97  307.00  308.62  150.75029        0.002143\n",
       "2017-08-17 09:00:00  308.62  312.00  308.62  310.00  469.27879        0.004472"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>actual_returns</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-01-23 18:00:00</th>\n",
       "      <td>1629.03</td>\n",
       "      <td>1640.49</td>\n",
       "      <td>1626.06</td>\n",
       "      <td>1628.85</td>\n",
       "      <td>26815.5440</td>\n",
       "      <td>-0.000104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-23 19:00:00</th>\n",
       "      <td>1628.85</td>\n",
       "      <td>1630.57</td>\n",
       "      <td>1610.04</td>\n",
       "      <td>1619.88</td>\n",
       "      <td>27357.8436</td>\n",
       "      <td>-0.005507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-23 20:00:00</th>\n",
       "      <td>1619.89</td>\n",
       "      <td>1635.26</td>\n",
       "      <td>1618.65</td>\n",
       "      <td>1634.80</td>\n",
       "      <td>13128.4739</td>\n",
       "      <td>0.009211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-23 21:00:00</th>\n",
       "      <td>1634.80</td>\n",
       "      <td>1635.50</td>\n",
       "      <td>1629.53</td>\n",
       "      <td>1631.84</td>\n",
       "      <td>9298.6748</td>\n",
       "      <td>-0.001811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-01-23 22:00:00</th>\n",
       "      <td>1631.84</td>\n",
       "      <td>1635.75</td>\n",
       "      <td>1630.90</td>\n",
       "      <td>1632.64</td>\n",
       "      <td>5790.1341</td>\n",
       "      <td>0.000490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        open     high      low    close      volume  \\\n",
       "timestamp                                                             \n",
       "2023-01-23 18:00:00  1629.03  1640.49  1626.06  1628.85  26815.5440   \n",
       "2023-01-23 19:00:00  1628.85  1630.57  1610.04  1619.88  27357.8436   \n",
       "2023-01-23 20:00:00  1619.89  1635.26  1618.65  1634.80  13128.4739   \n",
       "2023-01-23 21:00:00  1634.80  1635.50  1629.53  1631.84   9298.6748   \n",
       "2023-01-23 22:00:00  1631.84  1635.75  1630.90  1632.64   5790.1341   \n",
       "\n",
       "                     actual_returns  \n",
       "timestamp                            \n",
       "2023-01-23 18:00:00       -0.000104  \n",
       "2023-01-23 19:00:00       -0.005507  \n",
       "2023-01-23 20:00:00        0.009211  \n",
       "2023-01-23 21:00:00       -0.001811  \n",
       "2023-01-23 22:00:00        0.000490  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate the daily returns using the closing prices and the pct_change function\n",
    "trading_df[\"actual_returns\"] = trading_df[\"close\"].pct_change()\n",
    "\n",
    "# Drop all NaN values from the DataFrame\n",
    "trading_df = trading_df.dropna()\n",
    "\n",
    "# Review the DataFrame\n",
    "display(trading_df.head())\n",
    "display(trading_df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import finta as ft\n",
    "from finta import TA\n",
    "import talib\n",
    "\n",
    "ohlcv_df = trading_df\n",
    "\n",
    "# List of time periods to use for Moving Averages calculation\n",
    "timeperiods = [5,7,14,20,30,50,70,100,150,200]\n",
    "\n",
    "df = ohlcv_df.copy()\n",
    "\n",
    "# Calculate SMAs and add them to the DataFrame\n",
    "for t in timeperiods:\n",
    "    #tsma = TA.SMA(df, t).shift(1)\n",
    "    sma = TA.SMA(df, t)\n",
    "    ema = TA.EMA(df, t)\n",
    "    atr = TA.ATR(df, t)  #Average True Range\n",
    "    adx = TA.ADX(df, t) \n",
    "    rsi = TA.RSI(df, t)\n",
    "    hma = TA.HMA(df, t)\n",
    "    vama = TA.VAMA(df, t)\n",
    " \n",
    "    # calculate the Force Index\n",
    "    force_index = pd.Series(df['close'].diff(1) * df['volume'], index=df.index)\n",
    "    force_ema = force_index.ewm(span=t, min_periods=0, adjust=True, ignore_na=False).mean()    \n",
    "    \n",
    "    #df['force_index'] = force_index\n",
    "    #df[f'force_index_ema_{t}'] = force_ema # add the Force Index and its EMA to the DataFrame\n",
    "    #df[f'TSMA_{t}'] = tsma\n",
    "    df[f'SMA_{t}'] = sma\n",
    "    df[f'EMA_{t}'] = ema\n",
    "    df[f'HMA_{t}'] = hma\n",
    "    df[f'VAMA_{t}'] = vama\n",
    "    df[f'ATR_{t}'] = atr\n",
    "    df[f'ADX_{t}'] = adx\n",
    "    df[f'RSI_{t}'] = rsi\n",
    "    \n",
    "    \n",
    "# Calculate the Parabolic SAR\n",
    "#sar = TA.PSAR(df)\n",
    "\n",
    "# Add the SAR values and trend direction to the DataFrame\n",
    "#df['sar'] = sar['psar']\n",
    "#df['psarbear'] = sar['psarbear']\n",
    "#df['psarbull'] = sar['psarbull']\n",
    "\n",
    "df['UO'] = TA.UO(df)\n",
    "\n",
    "# Adding Awesome Indicator (AO)\n",
    "df['AO'] = TA.AO(df)\n",
    "df['OBV'] =TA.OBV(df)\n",
    "\n",
    "# Adding Chaikin Indicator \n",
    "df['CHAIKIN'] = TA.CHAIKIN(df)\n",
    "\n",
    "# Adding Bollinger Bands\n",
    "df[['BB_UPPER','BB_MED','BB_LOWER']] =TA.BBANDS(df)\n",
    "\n",
    "# Calculate the Keltner Channel with TALIB\n",
    "#df[['KC_UPPER','KC_MED','KC_LOWER']] = TA.KC(df)\n",
    "\n",
    "# calculate Commodity Channel Index (CCI)\n",
    "df['cci'] = TA.CCI(df)\n",
    "\n",
    "# assuming you have OHLCV data in a pandas dataframe called \"df\"\n",
    "#volume_momentum = talib.MOM(df['volume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# calculate the Ichimoku Kinko Hyo indicator\n",
    "# Calculate the conversion line\n",
    "nine_period_high = df['high'].rolling(window=9).max()\n",
    "nine_period_low = df['low'].rolling(window=9).min()\n",
    "df['tenkan_sen'] = (nine_period_high + nine_period_low) / 2\n",
    "\n",
    "# Calculate the base line\n",
    "periods = 26\n",
    "twenty_six_period_high = df['high'].rolling(window=periods).max()\n",
    "twenty_six_period_low = df['low'].rolling(window=periods).min()\n",
    "df['kijun_sen'] = (twenty_six_period_high + twenty_six_period_low) / 2\n",
    "\n",
    "# Calculate the leading span A\n",
    "df['senkou_span_a'] = ((df['tenkan_sen'] + df['kijun_sen']) / 2).shift(periods=periods)\n",
    "\n",
    "# Calculate the leading span B\n",
    "periods2 = 52\n",
    "fifty_two_period_high = df['high'].rolling(window=periods2).max()\n",
    "fifty_two_period_low = df['low'].rolling(window=periods2).min()\n",
    "df['senkou_span_b'] = ((fifty_two_period_high + fifty_two_period_low) / 2).shift(periods=periods)\n",
    "\n",
    "# Calculate the lagging span\n",
    "df['chikou_span'] = df['close'].shift(periods=-periods)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add a daily return values column to the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>actual_returns</th>\n",
       "      <th>SMA_5</th>\n",
       "      <th>EMA_5</th>\n",
       "      <th>HMA_5</th>\n",
       "      <th>VAMA_5</th>\n",
       "      <th>...</th>\n",
       "      <th>CHAIKIN</th>\n",
       "      <th>BB_UPPER</th>\n",
       "      <th>BB_MED</th>\n",
       "      <th>BB_LOWER</th>\n",
       "      <th>cci</th>\n",
       "      <th>tenkan_sen</th>\n",
       "      <th>kijun_sen</th>\n",
       "      <th>senkou_span_a</th>\n",
       "      <th>senkou_span_b</th>\n",
       "      <th>chikou_span</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-09-02 19:00:00</th>\n",
       "      <td>340.23</td>\n",
       "      <td>341.47</td>\n",
       "      <td>334.93</td>\n",
       "      <td>336.18</td>\n",
       "      <td>234.99340</td>\n",
       "      <td>-0.009166</td>\n",
       "      <td>339.158</td>\n",
       "      <td>339.736879</td>\n",
       "      <td>337.449778</td>\n",
       "      <td>339.376015</td>\n",
       "      <td>...</td>\n",
       "      <td>-137.517059</td>\n",
       "      <td>393.172933</td>\n",
       "      <td>357.5685</td>\n",
       "      <td>321.964067</td>\n",
       "      <td>-102.539757</td>\n",
       "      <td>343.685</td>\n",
       "      <td>360.705</td>\n",
       "      <td>388.9250</td>\n",
       "      <td>384.305</td>\n",
       "      <td>341.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-02 20:00:00</th>\n",
       "      <td>338.08</td>\n",
       "      <td>338.47</td>\n",
       "      <td>325.63</td>\n",
       "      <td>325.63</td>\n",
       "      <td>452.29677</td>\n",
       "      <td>-0.031382</td>\n",
       "      <td>335.940</td>\n",
       "      <td>335.034586</td>\n",
       "      <td>328.105556</td>\n",
       "      <td>334.957058</td>\n",
       "      <td>...</td>\n",
       "      <td>-282.506411</td>\n",
       "      <td>388.022171</td>\n",
       "      <td>354.1340</td>\n",
       "      <td>320.245829</td>\n",
       "      <td>-133.249723</td>\n",
       "      <td>342.955</td>\n",
       "      <td>359.975</td>\n",
       "      <td>389.2000</td>\n",
       "      <td>385.245</td>\n",
       "      <td>341.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-02 21:00:00</th>\n",
       "      <td>327.16</td>\n",
       "      <td>331.08</td>\n",
       "      <td>320.08</td>\n",
       "      <td>324.00</td>\n",
       "      <td>236.00212</td>\n",
       "      <td>-0.005006</td>\n",
       "      <td>333.346</td>\n",
       "      <td>331.356391</td>\n",
       "      <td>320.744222</td>\n",
       "      <td>332.311002</td>\n",
       "      <td>...</td>\n",
       "      <td>-337.709600</td>\n",
       "      <td>384.387306</td>\n",
       "      <td>351.1105</td>\n",
       "      <td>317.833694</td>\n",
       "      <td>-139.374949</td>\n",
       "      <td>338.830</td>\n",
       "      <td>357.200</td>\n",
       "      <td>389.2000</td>\n",
       "      <td>386.085</td>\n",
       "      <td>341.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-02 22:00:00</th>\n",
       "      <td>325.45</td>\n",
       "      <td>340.10</td>\n",
       "      <td>325.45</td>\n",
       "      <td>329.72</td>\n",
       "      <td>229.42859</td>\n",
       "      <td>0.017654</td>\n",
       "      <td>330.964</td>\n",
       "      <td>330.810927</td>\n",
       "      <td>324.167778</td>\n",
       "      <td>329.932132</td>\n",
       "      <td>...</td>\n",
       "      <td>-360.037586</td>\n",
       "      <td>379.516187</td>\n",
       "      <td>348.4625</td>\n",
       "      <td>317.408813</td>\n",
       "      <td>-93.896395</td>\n",
       "      <td>337.920</td>\n",
       "      <td>357.200</td>\n",
       "      <td>389.3675</td>\n",
       "      <td>386.085</td>\n",
       "      <td>333.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-02 23:00:00</th>\n",
       "      <td>331.77</td>\n",
       "      <td>343.15</td>\n",
       "      <td>329.72</td>\n",
       "      <td>343.14</td>\n",
       "      <td>280.21839</td>\n",
       "      <td>0.040701</td>\n",
       "      <td>331.734</td>\n",
       "      <td>334.920618</td>\n",
       "      <td>338.516000</td>\n",
       "      <td>331.607894</td>\n",
       "      <td>...</td>\n",
       "      <td>-247.413454</td>\n",
       "      <td>374.386794</td>\n",
       "      <td>346.6935</td>\n",
       "      <td>319.000206</td>\n",
       "      <td>-50.887796</td>\n",
       "      <td>332.675</td>\n",
       "      <td>357.200</td>\n",
       "      <td>389.3675</td>\n",
       "      <td>386.085</td>\n",
       "      <td>335.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 89 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       open    high     low   close     volume  \\\n",
       "timestamp                                                        \n",
       "2017-09-02 19:00:00  340.23  341.47  334.93  336.18  234.99340   \n",
       "2017-09-02 20:00:00  338.08  338.47  325.63  325.63  452.29677   \n",
       "2017-09-02 21:00:00  327.16  331.08  320.08  324.00  236.00212   \n",
       "2017-09-02 22:00:00  325.45  340.10  325.45  329.72  229.42859   \n",
       "2017-09-02 23:00:00  331.77  343.15  329.72  343.14  280.21839   \n",
       "\n",
       "                     actual_returns    SMA_5       EMA_5       HMA_5  \\\n",
       "timestamp                                                              \n",
       "2017-09-02 19:00:00       -0.009166  339.158  339.736879  337.449778   \n",
       "2017-09-02 20:00:00       -0.031382  335.940  335.034586  328.105556   \n",
       "2017-09-02 21:00:00       -0.005006  333.346  331.356391  320.744222   \n",
       "2017-09-02 22:00:00        0.017654  330.964  330.810927  324.167778   \n",
       "2017-09-02 23:00:00        0.040701  331.734  334.920618  338.516000   \n",
       "\n",
       "                         VAMA_5  ...     CHAIKIN    BB_UPPER    BB_MED  \\\n",
       "timestamp                        ...                                     \n",
       "2017-09-02 19:00:00  339.376015  ... -137.517059  393.172933  357.5685   \n",
       "2017-09-02 20:00:00  334.957058  ... -282.506411  388.022171  354.1340   \n",
       "2017-09-02 21:00:00  332.311002  ... -337.709600  384.387306  351.1105   \n",
       "2017-09-02 22:00:00  329.932132  ... -360.037586  379.516187  348.4625   \n",
       "2017-09-02 23:00:00  331.607894  ... -247.413454  374.386794  346.6935   \n",
       "\n",
       "                       BB_LOWER         cci  tenkan_sen  kijun_sen  \\\n",
       "timestamp                                                            \n",
       "2017-09-02 19:00:00  321.964067 -102.539757     343.685    360.705   \n",
       "2017-09-02 20:00:00  320.245829 -133.249723     342.955    359.975   \n",
       "2017-09-02 21:00:00  317.833694 -139.374949     338.830    357.200   \n",
       "2017-09-02 22:00:00  317.408813  -93.896395     337.920    357.200   \n",
       "2017-09-02 23:00:00  319.000206  -50.887796     332.675    357.200   \n",
       "\n",
       "                     senkou_span_a  senkou_span_b  chikou_span  \n",
       "timestamp                                                       \n",
       "2017-09-02 19:00:00       388.9250        384.305       341.71  \n",
       "2017-09-02 20:00:00       389.2000        385.245       341.38  \n",
       "2017-09-02 21:00:00       389.2000        386.085       341.77  \n",
       "2017-09-02 22:00:00       389.3675        386.085       333.09  \n",
       "2017-09-02 23:00:00       389.3675        386.085       335.65  \n",
       "\n",
       "[5 rows x 89 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the daily returns using the closing prices and the pct_change function\n",
    "df[\"actual_returns\"] = df[\"close\"].pct_change()\n",
    "\n",
    "# Drop all NaN values from the DataFrame\n",
    "df = df.dropna()\n",
    "\n",
    "# Review the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a new column in the trading_df called signal setting its value to zero.\n",
    "df[\"signal\"] = 0.0\n",
    "\n",
    "# Create the signal to buy\n",
    "df.loc[(df[\"actual_returns\"] >= 0), \"signal\"] = 1\n",
    "\n",
    "# Create the signal to sell\n",
    "df.loc[(df[\"actual_returns\"] < 0), \"signal\"] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0    23777\n",
       "-1.0    23206\n",
       "Name: signal, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"signal\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Pre-Processing\n",
    "### 3.1 Dealing with Class Imbalance using Undersampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Count the number of samples in each class\n",
    "class_counts = df['signal'].value_counts()\n",
    "\n",
    "# Find the class with fewer samples\n",
    "minority_class = class_counts.idxmin()\n",
    "\n",
    "# Split the dataframe into the majority and minority classes\n",
    "majority_class = df[df['signal'] != minority_class]\n",
    "minority_class = df[df['signal'] == minority_class]\n",
    "\n",
    "# Undersample the majority class to match the number of samples in the minority class\n",
    "undersampled_majority = resample(majority_class,\n",
    "                                 replace=False,\n",
    "                                 n_samples=len(minority_class),\n",
    "                                 random_state=42)\n",
    "\n",
    "# Combine the undersampled majority class with the minority class\n",
    "balanced_df = pd.concat([undersampled_majority, minority_class])\n",
    "\n",
    "# Shuffle the rows in the balanced dataframe\n",
    "balanced_df = balanced_df.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The class imbalance method (undersampling) was applied, but it did not improve the results significantly, particularly for the Test dataset's ROC curve. Uncommenting the line below will allow for the option to skip the undersampling method for the remainder of the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "balanced_df = df #comment this line if you want to use balanced classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0    23777\n",
       "-1.0    23206\n",
       "Name: signal, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df[\"signal\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "### 3.2 Generating the Feature and Target datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating X as predictors (features) dataset\n",
    "X= balanced_df.copy()\n",
    "\n",
    "# Removing columns indicative of previous prices\n",
    "# & shifting X one row down to avoid using data not available to us at the time of prediction\n",
    "X= X.drop([\"open\",\"high\",\"low\",\"close\",\"volume\",\"actual_returns\",\"signal\"], axis =1).shift().dropna().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMA_5</th>\n",
       "      <th>EMA_5</th>\n",
       "      <th>HMA_5</th>\n",
       "      <th>VAMA_5</th>\n",
       "      <th>ATR_5</th>\n",
       "      <th>ADX_5</th>\n",
       "      <th>RSI_5</th>\n",
       "      <th>SMA_7</th>\n",
       "      <th>EMA_7</th>\n",
       "      <th>HMA_7</th>\n",
       "      <th>...</th>\n",
       "      <th>CHAIKIN</th>\n",
       "      <th>BB_UPPER</th>\n",
       "      <th>BB_MED</th>\n",
       "      <th>BB_LOWER</th>\n",
       "      <th>cci</th>\n",
       "      <th>tenkan_sen</th>\n",
       "      <th>kijun_sen</th>\n",
       "      <th>senkou_span_a</th>\n",
       "      <th>senkou_span_b</th>\n",
       "      <th>chikou_span</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-09-02 20:00:00</th>\n",
       "      <td>339.158</td>\n",
       "      <td>339.736879</td>\n",
       "      <td>337.449778</td>\n",
       "      <td>339.376015</td>\n",
       "      <td>11.534</td>\n",
       "      <td>77.693325</td>\n",
       "      <td>31.151460</td>\n",
       "      <td>340.600000</td>\n",
       "      <td>341.680162</td>\n",
       "      <td>337.664603</td>\n",
       "      <td>...</td>\n",
       "      <td>-137.517059</td>\n",
       "      <td>393.172933</td>\n",
       "      <td>357.5685</td>\n",
       "      <td>321.964067</td>\n",
       "      <td>-102.539757</td>\n",
       "      <td>343.685</td>\n",
       "      <td>360.705</td>\n",
       "      <td>388.9250</td>\n",
       "      <td>384.305</td>\n",
       "      <td>341.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-02 21:00:00</th>\n",
       "      <td>335.940</td>\n",
       "      <td>335.034586</td>\n",
       "      <td>328.105556</td>\n",
       "      <td>334.957058</td>\n",
       "      <td>10.518</td>\n",
       "      <td>79.661445</td>\n",
       "      <td>20.476812</td>\n",
       "      <td>336.677143</td>\n",
       "      <td>337.667621</td>\n",
       "      <td>330.740873</td>\n",
       "      <td>...</td>\n",
       "      <td>-282.506411</td>\n",
       "      <td>388.022171</td>\n",
       "      <td>354.1340</td>\n",
       "      <td>320.245829</td>\n",
       "      <td>-133.249723</td>\n",
       "      <td>342.955</td>\n",
       "      <td>359.975</td>\n",
       "      <td>389.2000</td>\n",
       "      <td>385.245</td>\n",
       "      <td>341.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-02 22:00:00</th>\n",
       "      <td>333.346</td>\n",
       "      <td>331.356391</td>\n",
       "      <td>320.744222</td>\n",
       "      <td>332.311002</td>\n",
       "      <td>10.104</td>\n",
       "      <td>81.864543</td>\n",
       "      <td>19.205792</td>\n",
       "      <td>335.060000</td>\n",
       "      <td>334.250716</td>\n",
       "      <td>323.166786</td>\n",
       "      <td>...</td>\n",
       "      <td>-337.709600</td>\n",
       "      <td>384.387306</td>\n",
       "      <td>351.1105</td>\n",
       "      <td>317.833694</td>\n",
       "      <td>-139.374949</td>\n",
       "      <td>338.830</td>\n",
       "      <td>357.200</td>\n",
       "      <td>389.2000</td>\n",
       "      <td>386.085</td>\n",
       "      <td>341.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-02 23:00:00</th>\n",
       "      <td>330.964</td>\n",
       "      <td>330.810927</td>\n",
       "      <td>324.167778</td>\n",
       "      <td>329.932132</td>\n",
       "      <td>10.858</td>\n",
       "      <td>71.317552</td>\n",
       "      <td>36.496297</td>\n",
       "      <td>333.345714</td>\n",
       "      <td>333.118037</td>\n",
       "      <td>322.624325</td>\n",
       "      <td>...</td>\n",
       "      <td>-360.037586</td>\n",
       "      <td>379.516187</td>\n",
       "      <td>348.4625</td>\n",
       "      <td>317.408813</td>\n",
       "      <td>-93.896395</td>\n",
       "      <td>337.920</td>\n",
       "      <td>357.200</td>\n",
       "      <td>389.3675</td>\n",
       "      <td>386.085</td>\n",
       "      <td>333.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-03 00:00:00</th>\n",
       "      <td>331.734</td>\n",
       "      <td>334.920618</td>\n",
       "      <td>338.516000</td>\n",
       "      <td>331.607894</td>\n",
       "      <td>11.982</td>\n",
       "      <td>60.038337</td>\n",
       "      <td>60.983606</td>\n",
       "      <td>334.227143</td>\n",
       "      <td>335.623528</td>\n",
       "      <td>332.935833</td>\n",
       "      <td>...</td>\n",
       "      <td>-247.413454</td>\n",
       "      <td>374.386794</td>\n",
       "      <td>346.6935</td>\n",
       "      <td>319.000206</td>\n",
       "      <td>-50.887796</td>\n",
       "      <td>332.675</td>\n",
       "      <td>357.200</td>\n",
       "      <td>389.3675</td>\n",
       "      <td>386.085</td>\n",
       "      <td>335.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       SMA_5       EMA_5       HMA_5      VAMA_5   ATR_5  \\\n",
       "timestamp                                                                  \n",
       "2017-09-02 20:00:00  339.158  339.736879  337.449778  339.376015  11.534   \n",
       "2017-09-02 21:00:00  335.940  335.034586  328.105556  334.957058  10.518   \n",
       "2017-09-02 22:00:00  333.346  331.356391  320.744222  332.311002  10.104   \n",
       "2017-09-02 23:00:00  330.964  330.810927  324.167778  329.932132  10.858   \n",
       "2017-09-03 00:00:00  331.734  334.920618  338.516000  331.607894  11.982   \n",
       "\n",
       "                         ADX_5      RSI_5       SMA_7       EMA_7       HMA_7  \\\n",
       "timestamp                                                                       \n",
       "2017-09-02 20:00:00  77.693325  31.151460  340.600000  341.680162  337.664603   \n",
       "2017-09-02 21:00:00  79.661445  20.476812  336.677143  337.667621  330.740873   \n",
       "2017-09-02 22:00:00  81.864543  19.205792  335.060000  334.250716  323.166786   \n",
       "2017-09-02 23:00:00  71.317552  36.496297  333.345714  333.118037  322.624325   \n",
       "2017-09-03 00:00:00  60.038337  60.983606  334.227143  335.623528  332.935833   \n",
       "\n",
       "                     ...     CHAIKIN    BB_UPPER    BB_MED    BB_LOWER  \\\n",
       "timestamp            ...                                                 \n",
       "2017-09-02 20:00:00  ... -137.517059  393.172933  357.5685  321.964067   \n",
       "2017-09-02 21:00:00  ... -282.506411  388.022171  354.1340  320.245829   \n",
       "2017-09-02 22:00:00  ... -337.709600  384.387306  351.1105  317.833694   \n",
       "2017-09-02 23:00:00  ... -360.037586  379.516187  348.4625  317.408813   \n",
       "2017-09-03 00:00:00  ... -247.413454  374.386794  346.6935  319.000206   \n",
       "\n",
       "                            cci  tenkan_sen  kijun_sen  senkou_span_a  \\\n",
       "timestamp                                                               \n",
       "2017-09-02 20:00:00 -102.539757     343.685    360.705       388.9250   \n",
       "2017-09-02 21:00:00 -133.249723     342.955    359.975       389.2000   \n",
       "2017-09-02 22:00:00 -139.374949     338.830    357.200       389.2000   \n",
       "2017-09-02 23:00:00  -93.896395     337.920    357.200       389.3675   \n",
       "2017-09-03 00:00:00  -50.887796     332.675    357.200       389.3675   \n",
       "\n",
       "                     senkou_span_b  chikou_span  \n",
       "timestamp                                        \n",
       "2017-09-02 20:00:00        384.305       341.71  \n",
       "2017-09-02 21:00:00        385.245       341.38  \n",
       "2017-09-02 22:00:00        386.085       341.77  \n",
       "2017-09-02 23:00:00        386.085       333.09  \n",
       "2017-09-03 00:00:00        386.085       335.65  \n",
       "\n",
       "[5 rows x 83 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the target set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copy the new signal column to a new Series called y.\n",
    "y = balanced_df[\"signal\"].copy()\n",
    "\n",
    "# keeping y and X the same size \n",
    "y = y[X.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### QC of X,y shape and content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46982, 83)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46982,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1.0    23777\n",
       "-1.0    23205\n",
       "Name: signal, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SMA_5', 'EMA_5', 'HMA_5', 'VAMA_5', 'ATR_5', 'ADX_5', 'RSI_5', 'SMA_7',\n",
       "       'EMA_7', 'HMA_7', 'VAMA_7', 'ATR_7', 'ADX_7', 'RSI_7', 'SMA_14',\n",
       "       'EMA_14', 'HMA_14', 'VAMA_14', 'ATR_14', 'ADX_14', 'RSI_14', 'SMA_20',\n",
       "       'EMA_20', 'HMA_20', 'VAMA_20', 'ATR_20', 'ADX_20', 'RSI_20', 'SMA_30',\n",
       "       'EMA_30', 'HMA_30', 'VAMA_30', 'ATR_30', 'ADX_30', 'RSI_30', 'SMA_50',\n",
       "       'EMA_50', 'HMA_50', 'VAMA_50', 'ATR_50', 'ADX_50', 'RSI_50', 'SMA_70',\n",
       "       'EMA_70', 'HMA_70', 'VAMA_70', 'ATR_70', 'ADX_70', 'RSI_70', 'SMA_100',\n",
       "       'EMA_100', 'HMA_100', 'VAMA_100', 'ATR_100', 'ADX_100', 'RSI_100',\n",
       "       'SMA_150', 'EMA_150', 'HMA_150', 'VAMA_150', 'ATR_150', 'ADX_150',\n",
       "       'RSI_150', 'SMA_200', 'EMA_200', 'HMA_200', 'VAMA_200', 'ATR_200',\n",
       "       'ADX_200', 'RSI_200', 'UO', 'AO', 'OBV', 'CHAIKIN', 'BB_UPPER',\n",
       "       'BB_MED', 'BB_LOWER', 'cci', 'tenkan_sen', 'kijun_sen', 'senkou_span_a',\n",
       "       'senkou_span_b', 'chikou_span'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "### 3.3 Feature Selection \n",
    "####  Use RFE (Recursive Feature Elimination) to keep the best features, with logistic regression as base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a logistic regression model\n",
    "model = LogisticRegression(max_iter=1500)\n",
    "\n",
    "# Create an RFE model to select the best features\n",
    "rfe = RFE(model, n_features_to_select=15)\n",
    "\n",
    "# Fit the RFE model to the data\n",
    "rfe = rfe.fit(X, y)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features = X.columns[rfe.support_]\n",
    "\n",
    "# keep only specified columns in the dataframe\n",
    "#X = X.iloc[:, selected_features]\n",
    "X = X[selected_features]\n",
    "\n",
    "# Print the selected features\n",
    "print (\"Number of selected features:\", len(X.columns), \"\\nSelected features:\\n\",selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "''' keeping note of the best selected features: \n",
    "Selected features:\n",
    " Index(['EMA_5', 'HMA_5', 'RSI_5', 'HMA_14', 'VAMA_20', 'RSI_30', 'HMA_50',\n",
    "       'ATR_50', 'RSI_50', 'HMA_70', 'VAMA_70', 'RSI_70', 'RSI_100',\n",
    "       'tenkan_sen', 'chikou_span'],\n",
    "      dtype='object')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove highly-correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_feats = X.copy()\n",
    "# Calculate correlation matrix\n",
    "# calculate the correlation matrix of the features\n",
    "corr_matrix = df_feats.corr()\n",
    "\n",
    "# set the threshold for correlation value\n",
    "corr_threshold = 0.90\n",
    "\n",
    "# find the highly correlated features and drop them from the dataframe\n",
    "high_corr_features = np.where(corr_matrix.abs() > corr_threshold)\n",
    "high_corr_features = [(corr_matrix.columns[x], corr_matrix.columns[y]) for x, y in zip(*high_corr_features) if x != y and x < y]\n",
    "df_feats.drop([col[1] for col in high_corr_features], axis=1, inplace=True)\n",
    "\n",
    "# select the remaining features with low correlation\n",
    "low_corr_features = df_feats.columns.tolist()\n",
    "\n",
    "# print the low correlated features\n",
    "print(low_corr_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The removal of the highly correlated feature does not appear to improve the quality of the prediction. Commenting out the line below will result in keeping only the features with less correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#X = X[low_corr_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "### 3.4 Splitting data and creating train and test datasets using time offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "from pandas.tseries.offsets import DateOffset\n",
    "\n",
    "# Select the start of the training period\n",
    "training_begin = X.index.min()\n",
    "\n",
    "# Display the training begin date\n",
    "#print(training_begin)\n",
    "\n",
    "# Select the ending period for the training data with an offset of 36 months\n",
    "training_end = X.index.min() + DateOffset(months=24)\n",
    "\n",
    "# Display the training end date\n",
    "#print(training_end)\n",
    "\n",
    "# Generate the X_train and y_train DataFrames\n",
    "X_train = X.loc[training_begin:training_end]\n",
    "y_train = y.loc[training_begin:training_end]\n",
    "\n",
    "# Display sample data\n",
    "display(X_train.head())\n",
    "\n",
    "# Generate the X_test and y_test DataFrames\n",
    "X_test = X.loc[training_end:]\n",
    "y_test = y.loc[training_end:]\n",
    "\n",
    "# Display sample data\n",
    "display(X_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### 3.5 Standardizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    " \n",
    "# Apply the scaler model to fit the X-train data\n",
    "X_scaler = scaler.fit(X_train)\n",
    " \n",
    "# Transform the X_train and X_test DataFrames using the X_scaler\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. ML models \n",
    "#### 4.1 XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "#from xgboost import xgbClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#replace -1 by 0 as xgboost expects a boolean target vector (only 0 and 1)\n",
    "y_train = y_train.replace(-1, 0)\n",
    "y_test = y_test.replace(-1, 0)\n",
    "\n",
    "# Create a xgb Classifier model\n",
    "xgb_clf = xgb.XGBClassifier(reg_alpha=27)\n",
    "\n",
    "xgb_clf.fit(X_train_scaled, y_train) \n",
    "\n",
    "# Use the best model to make predictions on the test data\n",
    "y_pred_xgb = xgb_clf.predict(X_test_scaled)\n",
    "\n",
    "ROC(xgb_clf,X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the trading fee as a decimal\n",
    "trading_fee = 0.00075\n",
    "classifier = xgb_clf\n",
    "\n",
    "# Backtest using our exteranl function\n",
    "xgb_predictions_df = Backtesting (df, X_test, X_test_scaled, classifier,trading_fee)\n",
    "\n",
    "# Calculate and plot the cumulative returns for the `actual_returns` and the `trading_algorithm_returns`\n",
    "(1 + xgb_predictions_df[[\"actual_returns\", \"trading_algorithm_returns\"]]).cumprod().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 4.2 CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from catboost import CatBoostClassifier\n",
    "# Initialize the CatBoost model\n",
    "\n",
    "cb_clf = CatBoostClassifier(iterations=450,random_state=seed  ,l2_leaf_reg=55.8, verbose = False)\n",
    "\n",
    "# Train the model on the training data\n",
    "cb_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# display ROC and classification metrics \n",
    "ROC(cb_clf,X_train_scaled, X_test_scaled, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the trading fee as a decimal\n",
    "trading_fee = 0.00075\n",
    "classifier = cb_clf\n",
    "\n",
    "# Backtest using our exteranl function\n",
    "cb_predictions_df = Backtesting (df, X_test, X_test_scaled, classifier,trading_fee)\n",
    "\n",
    "# Calculate and plot the cumulative returns for the `actual_returns` and the `trading_algorithm_returns`\n",
    "(1 + cb_predictions_df[[\"actual_returns\", \"trading_algorithm_returns\"]]).cumprod().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 4.3 LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "# create LDA object and fit the model\n",
    "lda = LinearDiscriminantAnalysis(n_components=1)\n",
    "\n",
    "# Train the model on the training data\n",
    "lda.fit_transform(X_train_scaled, y_train)\n",
    "\n",
    "ROC(lda,X_train_scaled, X_test_scaled, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the trading fee as a decimal\n",
    "trading_fee = 0.00075\n",
    "classifier = lda\n",
    "\n",
    "# Backtest using our exteranl function\n",
    "lda_predictions_df = Backtesting (df, X_test, X_test_scaled, classifier,trading_fee)\n",
    "\n",
    "# Calculate and plot the cumulative returns for the `actual_returns` and the `trading_algorithm_returns`\n",
    "(1 + lda_predictions_df[[\"actual_returns\", \"trading_algorithm_returns\"]]).cumprod().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> LDA model seems way too good to be true. I'm not sure whether I'm using properly this algorithm or not. I still need to research more about it. This behavior makes me doubt about the quality of my selected features, as it looks like I'm using some data here for prediction that I don't have access to (data from the future) which can lead to an anormaly good behavior. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 4.4 Model Building helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These utilities are helpful for identifying the best models and understanding them better. However, they may take a long time to run. If needed, you can interrupt their execution as they are not essential for the machine learning process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting best performing model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_selection(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Resample X_test\n",
    "upscaled_X_test = X_test.resample('1D').interpolate(method='linear')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define which classifier to use \n",
    "clf = xgb_clf\n",
    "\n",
    "\n",
    "# Initialize SHAP explainer\n",
    "explainer = shap.Explainer(clf.predict, upscaled_X_test)\n",
    "\n",
    "# Calculate SHAP values\n",
    "shap_values = explainer(upscaled_X_test)\n",
    "\n",
    "shap.summary_plot(shap_values, upscaled_X_test, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SHAP Analysis \n",
    "# define which classifier to use \n",
    "clf = cb_clf\n",
    "\n",
    "# Initialize SHAP explainer\n",
    "explainer = shap.Explainer(clf.predict, upscaled_X_test)\n",
    "\n",
    "# Calculate SHAP values\n",
    "shap_values = explainer(upscaled_X_test)\n",
    "\n",
    "shap.summary_plot(shap_values, upscaled_X_test, plot_type=\"bar\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev310",
   "language": "python",
   "name": "dev310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
