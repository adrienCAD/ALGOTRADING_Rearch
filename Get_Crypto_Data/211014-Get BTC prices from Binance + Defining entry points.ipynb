{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f2b5f970",
   "metadata": {},
   "source": [
    "# AlphaJet - MVP3 \n",
    "## Part #1 - Grab latest BTC price and create MAs, Bollinger bands and RSI features\n",
    "#### Sources : \n",
    "\n",
    "##### ML for Algo Trading - Stefan Jansen book\n",
    "##### Medium article \"Retrieving Full Historical Data for Every Cryptocurrency on Binance & BitMex Using the Python API\" from Peter Nistrup\n",
    "https://betterprogramming.pub/easiest-way-to-use-the-bitmex-api-with-python-fbf66dc38633"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4db8ee77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas_datareader.data as web\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import talib\n",
    "import quandl\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "from datetime import date,timedelta, datetime\n",
    "import math\n",
    "import os.path\n",
    "import time\n",
    "from bitmex import bitmex\n",
    "from binance.client import Client\n",
    "from dateutil import parser\n",
    "from tqdm import tqdm_notebook #(Optional, used for progress-bars)\n",
    "#import pandas_profiling #Optional - for fancy data analysis reports!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ca08598",
   "metadata": {},
   "source": [
    "#### Defining API keys for Binance and Bitmex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75d64277",
   "metadata": {},
   "outputs": [],
   "source": [
    "### API\n",
    "bitmex_api_key = 'REDACTED'    #Enter your own API-key here\n",
    "bitmex_api_secret = '[REDACTED]' #Enter your own API-secret here\n",
    "binance_api_key = 'VaBzOEyR5SpRLCkWg2CBuBnlsAP6I0nEuVOFuO4AHO1IrDg7H3WNo2IizWBfCr03'    #Enter your own API-key here\n",
    "binance_api_secret = 'lgDl4hN89eJ8P7BhhHKQqX9DBTrA3peK4fDgJj6L8wsdyonCYI1XJTOoEs60IyRO' #Enter your own API-secret here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3bc22f61",
   "metadata": {},
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b05b6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "binsizes = {\"1m\": 1, \"5m\": 5, \"1h\": 60, \"1d\": 1440}\n",
    "batch_size = 750\n",
    "#bitmex_client = bitmex(test=False, api_key=bitmex_api_key, api_secret=bitmex_api_secret)\n",
    "binance_client = Client(api_key=binance_api_key, api_secret=binance_api_secret)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "39077a6d",
   "metadata": {},
   "source": [
    "### FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e340ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minutes_of_new_data(symbol, kline_size, data, source):\n",
    "    if len(data) > 0:  old = parser.parse(data[\"timestamp\"].iloc[-1])\n",
    "    elif source == \"binance\": old = datetime.strptime('1 Jan 2017', '%d %b %Y')\n",
    "    elif source == \"bitmex\": old = bitmex_client.Trade.Trade_getBucketed(symbol=symbol, binSize=kline_size, count=1, reverse=False).result()[0][0]['timestamp']\n",
    "    if source == \"binance\": new = pd.to_datetime(binance_client.get_klines(symbol=symbol, interval=kline_size)[-1][0], unit='ms')\n",
    "    if source == \"bitmex\": new = bitmex_client.Trade.Trade_getBucketed(symbol=symbol, binSize=kline_size, count=1, reverse=True).result()[0][0]['timestamp']\n",
    "    return old, new\n",
    "\n",
    "def get_all_binance(symbol, kline_size, save = False):\n",
    "    filename = '%s-%s-data.csv' % (symbol, kline_size)\n",
    "    if os.path.isfile(filename): data_df = pd.read_csv(filename)\n",
    "    else: data_df = pd.DataFrame()\n",
    "    oldest_point, newest_point = minutes_of_new_data(symbol, kline_size, data_df, source = \"binance\")\n",
    "    delta_min = (newest_point - oldest_point).total_seconds()/60\n",
    "    available_data = math.ceil(delta_min/binsizes[kline_size])\n",
    "    if oldest_point == datetime.strptime('1 Jan 2017', '%d %b %Y'): print('Downloading all available %s data for %s. Be patient..!' % (kline_size, symbol))\n",
    "    else: print('Downloading %d minutes of new data available for %s, i.e. %d instances of %s data.' % (delta_min, symbol, available_data, kline_size))\n",
    "    klines = binance_client.get_historical_klines(symbol, kline_size, oldest_point.strftime(\"%d %b %Y %H:%M:%S\"), newest_point.strftime(\"%d %b %Y %H:%M:%S\"))\n",
    "    data = pd.DataFrame(klines, columns = ['timestamp', 'open', 'high', 'low', 'close', 'volume', 'close_time', 'quote_av', 'trades', 'tb_base_av', 'tb_quote_av', 'ignore' ])\n",
    "    data['timestamp'] = pd.to_datetime(data['timestamp'], unit='ms')\n",
    "    if len(data_df) > 0:\n",
    "        temp_df = pd.DataFrame(data)\n",
    "        data_df = pd.concat([data_df, temp_df])\n",
    "        #data_df = data_df.append(temp_df)\n",
    "    else: data_df = data\n",
    "    data_df.set_index('timestamp', inplace=True)\n",
    "    if save: data_df.to_csv(filename)\n",
    "    print('All caught up..!')\n",
    "    return data_df\n",
    "\n",
    "def get_all_bitmex(symbol, kline_size, save = False):\n",
    "    filename = '%s-%s-data.csv' % (symbol, kline_size)\n",
    "    if os.path.isfile(filename): data_df = pd.read_csv(filename)\n",
    "    else: data_df = pd.DataFrame()\n",
    "    oldest_point, newest_point = minutes_of_new_data(symbol, kline_size, data_df, source = \"bitmex\")\n",
    "    delta_min = (newest_point - oldest_point).total_seconds()/60\n",
    "    available_data = math.ceil(delta_min/binsizes[kline_size])\n",
    "    rounds = math.ceil(available_data / batch_size)\n",
    "    if rounds > 0:\n",
    "        print('Downloading %d minutes of new data available for %s, i.e. %d instances of %s data in %d rounds.' % (delta_min, symbol, available_data, kline_size, rounds))\n",
    "        for round_num in tqdm_notebook(range(rounds)):\n",
    "            time.sleep(1)\n",
    "            new_time = (oldest_point + timedelta(minutes = round_num * batch_size * binsizes[kline_size]))\n",
    "            data = bitmex_client.Trade.Trade_getBucketed(symbol=symbol, binSize=kline_size, count=batch_size, startTime = new_time).result()[0]\n",
    "            temp_df = pd.DataFrame(data)\n",
    "            data_df = pd.concat([data_df, temp_df])\n",
    "            #data_df = data_df.append(temp_df)\n",
    "    data_df.set_index('timestamp', inplace=True)\n",
    "    if save and rounds > 0: data_df.to_csv(filename)\n",
    "    print('All caught up..!')\n",
    "    return data_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9ddfa9cb",
   "metadata": {},
   "source": [
    "# 1) Download Data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "394e660d",
   "metadata": {},
   "source": [
    "##### Getting the Data from Binance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6da8b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 50640 minutes of new data available for ETHUSDT, i.e. 844 instances of 1h data.\n",
      "All caught up..!\n"
     ]
    }
   ],
   "source": [
    "data = get_all_binance('ETHUSDT','1h',save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "135a2cbf-5786-4379-8e66-e82abd46a027",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 89400 minutes of new data available for ETHUSDT, i.e. 1490 instances of 1h data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x7/v571_3t12ddffkm6dh_29_tr0000gn/T/ipykernel_32597/3820235638.py:23: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data_df = data_df.append(temp_df)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All caught up..!\n"
     ]
    }
   ],
   "source": [
    "data = get_all_binance('ETHUSDT','1h',save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efbaa0c7-7521-4f59-90e4-2591bfe6fa78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data downloaded and saved as crypto_fear_and_greed_index.csv\n"
     ]
    }
   ],
   "source": [
    "# you can dowload fear and grid data from https://api.alternative.me/fng/?limit=30\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# API endpoint\n",
    "url = \"https://api.alternative.me/fng/?limit=0\"\n",
    "\n",
    "# Send request and get the response\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the JSON data\n",
    "    data = response.json()[\"data\"]\n",
    "    \n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Convert timestamp to datetime\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "    \n",
    "    # Set datetime as index\n",
    "    df.set_index('timestamp', inplace=True)\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv(\"crypto_fear_and_greed_index.csv\")\n",
    "    \n",
    "    print(\"Data downloaded and saved as crypto_fear_and_greed_index.csv\")\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10b9291",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(3)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1c4ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3d7970ca",
   "metadata": {},
   "source": [
    "##### using the last 30 days and cleaning up the original BTC file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21fe147",
   "metadata": {},
   "outputs": [],
   "source": [
    "#start_date = pd.to_datetime('5/1/2020 00:00', utc= True)\n",
    "#end_date = pd.to_datetime('8/1/2021 00:00', utc= True)\n",
    "#end_date = pd.to_datetime(datetime.now(), utc= True)\n",
    "#start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9369438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting index to proper datetime object\n",
    "data.index = pd.to_datetime(data.index)\n",
    "data.index = data.index.tz_localize('utc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21f20e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove any duplicate\n",
    "data = data.groupby(data.index).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bd69b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#price = data[(data.index >= start_date) & (data.index <= end_date)]\n",
    "price = data.tail(7600)\n",
    "\n",
    "price=price[['open','high','low','close','volume']]\n",
    "\n",
    "\n",
    "# Converts the header name to all uppercase\n",
    "price.columns = [x.capitalize() for x in price.columns] \n",
    "\n",
    "# Add AdjClose column\n",
    "price['AdjClose']=price['Close']\n",
    "\n",
    "# Changing columns to float\n",
    "price = price.astype(float)\n",
    "\n",
    "# Renaming index\n",
    "price.index.rename('Date', inplace=True)\n",
    "\n",
    "price.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4c912d",
   "metadata": {},
   "outputs": [],
   "source": [
    "price.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "67c50606",
   "metadata": {},
   "source": [
    "#### Adding Moving Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b284b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['5d_close_pct']  # a list of the feature names for later\n",
    "\n",
    "# Create moving averages and rsi for timeperiods of 5, 7, 14, 30, 50,100,200,350,700\n",
    "for n in [5,7,14,20,30,50,100,200,350,600,700]:\n",
    "\n",
    "    # Create the simple moving average indicator and divide by Adj_Close\n",
    "    price['ma' + str(n)] = talib.SMA(price['AdjClose'].values, timeperiod=n) \n",
    "    price['tsma'+ str(n)] = talib.TSF(price['AdjClose'].values, timeperiod=n)\n",
    "    price['tsma_norm'+ str(n)] = talib.TSF(price['AdjClose'].values, timeperiod=n)/price['AdjClose']\n",
    "    \n",
    "    # Create the exp moving average indicator and divide by Adj_Close\n",
    "    price['ema' + str(n)] = talib.EMA(price['AdjClose'].values,timeperiod=n) \n",
    "    \n",
    "    # Create the RSI indicator\n",
    "    price['rsi' + str(n)] = talib.RSI(price['AdjClose'].values, timeperiod=n)\n",
    "    \n",
    "    # Add previous close price for the n previous days, and n-day percentage % price change\n",
    "    price['previous'+ str(n)+'d_close'] = price['AdjClose'].shift(n) \n",
    "    price[str(n)+'d_close_pct'] = price['AdjClose'].pct_change(n)\n",
    "\n",
    "    # Add rsi, moving average, tsma and previous days close prices and % change to the feature name list\n",
    "    feature_names = feature_names + ['ma'+str(n),'tsma'+ str(n),'tsma_norm'+ str(n),'ema' + str(n), 'rsi' + str(n), 'previous'+str(n), str(n)+'d_close_pct']\n",
    "    \n",
    "\n",
    "print(feature_names)\n",
    "\n",
    "price.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17dc1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "price.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc159dca",
   "metadata": {},
   "source": [
    "#### Adding PPO and Bollinger Bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0935c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "close = price['AdjClose'].values\n",
    "up, mid, low = talib.BBANDS(close, timeperiod=14, nbdevup=2, nbdevdn=2, matype=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54c7a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate Bollinger bands for time period 14 days, using TAlib library \n",
    "\n",
    "up, mid, low = talib.BBANDS(close, timeperiod=14, nbdevup=2, nbdevdn=2, matype=0)\n",
    "price['BB_up'] = up\n",
    "price['BB_mid'] = mid\n",
    "price['BB_low'] = low\n",
    "price['BBP14'] = (price['AdjClose'] - low) / (up - low)\n",
    "price['BB_up_norm'] = up/price['AdjClose']\n",
    "price['BB_mid_norm'] = mid/price['AdjClose']\n",
    "price['BB_low_norm'] = low/price['AdjClose']\n",
    "price['BBP14_norm'] = price['BBP14']/price['AdjClose']\n",
    "\n",
    "\n",
    "# Add ppo indicators\n",
    "\n",
    "# create PPO Percentage Price Oscillator - normalized version of MACD for 20-day and 50-day exp moving average\n",
    "price['ppo20-50'] = talib.PPO(price['AdjClose'].values, fastperiod=20, slowperiod=50, matype=0) \n",
    "price['ppo50-100'] = talib.PPO(price['AdjClose'].values, fastperiod=50, slowperiod=100, matype=0)\n",
    "price['ppo7-20'] = talib.PPO(price['AdjClose'].values, fastperiod=7, slowperiod=20, matype=0) \n",
    "price['ppo100-200'] = talib.PPO(price['AdjClose'].values, fastperiod=100, slowperiod=200, matype=0) \n",
    "price['ppo200-350'] = talib.PPO(price['AdjClose'].values, fastperiod=200, slowperiod=350, matype=0) \n",
    "price['ppo100-700'] = talib.PPO(price['AdjClose'].values, fastperiod=100, slowperiod=700, matype=0) \n",
    "price['ppo20-200'] = talib.PPO(price['AdjClose'].values, fastperiod=20, slowperiod=200, matype=0) \n",
    "price['ppo50-350'] = talib.PPO(price['AdjClose'].values, fastperiod=50, slowperiod=350, matype=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00cb2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "price.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363c4db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "price.tail(70)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08d64e7c",
   "metadata": {},
   "source": [
    "## 2) Exporting to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4024cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting last 3 weeks of data\n",
    "Latest=price\n",
    "\n",
    "# datetime object containing current date and time\n",
    "now = datetime.now()\n",
    "\n",
    "# YYYY-mm-dd_HM\n",
    "date_string = now.strftime(\"%Y-%m-%d\")\n",
    "#Latest.to_csv(\"datasets_to_score/BTC_binance_\"+str(date_string)+\".csv\", index=True, header=True)\n",
    "Latest.to_csv(\"datasets_to_score/BTC_binance_\"+str(date_string)+\".csv\", index=True, header=True)\n",
    "\n",
    "print(\"'BTC_binance_\"+str(date_string)+\".csv' has been exported\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e22991",
   "metadata": {},
   "outputs": [],
   "source": [
    "Latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc0c431",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b949087f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a787d370",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424bbc56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
